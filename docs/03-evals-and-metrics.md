# ğŸ“Š DeÄŸerlendirme ve Metrikler Rehberi (Evals & Metrics)

## Neden Eval YapmalÄ±yÄ±z?

Bir agent "Ã§alÄ±ÅŸÄ±yor" demek yetmez. Åu sorularÄ± cevaplamalÄ±yÄ±z:
- **DoÄŸru mu?** GÃ¶revi gerÃ§ekten baÅŸarÄ±yla tamamlÄ±yor mu?
- **Ne kadar maliyetli?** Her gÃ¶rev iÃ§in ne kadar token/para harcÄ±yor?
- **Ne kadar hÄ±zlÄ±?** KullanÄ±cÄ± ne kadar bekliyor?
- **GÃ¼venilir mi?** 100 denemeden kaÃ§Ä±nda baÅŸarÄ±lÄ±?

---

## ğŸ“ Evaluation Seviyeleri

### Seviye 1: Unit Eval (Birim DeÄŸerlendirme)

Tek bir bileÅŸeni test eder:

```python
# Ã–rnek: Tool doÄŸru parametre ile Ã§aÄŸrÄ±lÄ±yor mu?
def test_tool_call_params():
    """Agent 'Ä°stanbul hava durumu' dediÄŸinde
    get_weather tool'unu city='Istanbul' ile Ã§aÄŸÄ±rmalÄ±"""
    
    result = agent.plan("Ä°stanbul'da hava nasÄ±l?")
    
    assert result.tool_name == "get_weather"
    assert result.params["city"] == "Istanbul"
```

### Seviye 2: Component Eval (BileÅŸen DeÄŸerlendirmesi)

Agent'Ä±n bir alt sistemini test eder:

```python
# Ã–rnek: Planner doÄŸru adÄ±mlarÄ± Ã¼retiyor mu?
def test_planner_steps():
    """KarmaÅŸÄ±k bir gÃ¶rev iÃ§in planner
    mantÄ±klÄ± adÄ±mlar Ã¼retmeli"""
    
    steps = planner.decompose("Blog yazÄ±sÄ± yaz ve yayÄ±nla")
    
    assert len(steps) >= 3
    assert any("araÅŸtÄ±r" in s.lower() for s in steps)
    assert any("yaz" in s.lower() for s in steps)
```

### Seviye 3: E2E Eval (UÃ§tan Uca DeÄŸerlendirme)

TÃ¼m sistemi test eder:

```python
# Ã–rnek: Agent gÃ¶revi baÅŸtan sona tamamlÄ±yor mu?
def test_e2e_weather_summary():
    """Agent hava durumu Ã¶zetini baÅŸarÄ±yla Ã¼retmeli"""
    
    result = agent.run("Ä°stanbul hava durumunu Ã¶zetle")
    
    assert result.status == "success"
    assert "Ä°stanbul" in result.output
    assert any(word in result.output for word in ["derece", "Â°C", "sÄ±caklÄ±k"])
```

---

## ğŸ“ Temel Metrikler

### 1. BaÅŸarÄ± OranÄ± (Success Rate)

```
BaÅŸarÄ± OranÄ± = BaÅŸarÄ±lÄ± GÃ¶revler / Toplam GÃ¶revler Ã— 100

Ã–rnek: 100 gÃ¶revden 87'si baÅŸarÄ±lÄ± â†’ %87 baÅŸarÄ± oranÄ±
```

**Hedef:** Production iÃ§in minimum %90+

### 2. Token Maliyeti (Token Cost)

```
GÃ¶rev Maliyeti = (Input Tokens Ã— Input FiyatÄ±) + (Output Tokens Ã— Output FiyatÄ±)

Ã–rnek (GPT-4o-mini):
  Input:  1500 token Ã— $0.15/1M = $0.000225
  Output:  500 token Ã— $0.60/1M = $0.000300
  Toplam: $0.000525 (~0.05 cent)
```

**Takip edilecek:** Ortalama gÃ¶rev maliyeti, en pahalÄ± gÃ¶revler

### 3. Gecikme (Latency)

```
Toplam SÃ¼re = LLM Ã‡aÄŸrÄ± SÃ¼resi + Tool Ã‡alÄ±ÅŸma SÃ¼resi + AÄŸ Gecikmesi

Ã–rnek:
  LLM Ã§aÄŸrÄ±sÄ±: 1.2s
  Tool Ã§aÄŸrÄ±sÄ±: 0.3s
  Ã— 3 dÃ¶ngÃ¼ iterasyonu
  Toplam: ~4.5s
```

**Hedef:** KullanÄ±cÄ±-etkileÅŸimli gÃ¶revler iÃ§in <10s

### 4. DÃ¶ngÃ¼ SayÄ±sÄ± (Loop Iterations)

```
KaÃ§ dÃ¶ngÃ¼de tamamlandÄ±?

Ä°deal:  1-3 dÃ¶ngÃ¼ (basit gÃ¶revler)
Normal: 3-5 dÃ¶ngÃ¼ (orta gÃ¶revler)
UyarÄ±:  5+ dÃ¶ngÃ¼ (sonsuz dÃ¶ngÃ¼ riski!)
```

### 5. Tool Ã‡aÄŸrÄ± BaÅŸarÄ±sÄ± (Tool Call Success)

```
Tool BaÅŸarÄ± OranÄ± = BaÅŸarÄ±lÄ± Tool Ã‡aÄŸrÄ±larÄ± / Toplam Tool Ã‡aÄŸrÄ±larÄ± Ã— 100

Hata Tipleri:
  - YanlÄ±ÅŸ tool seÃ§imi
  - HatalÄ± parametreler
  - Timeout
  - Tool hatasÄ±
```

---

## ğŸ”¬ Eval NasÄ±l YapÄ±lÄ±r?

### AdÄ±m 1: Test SenaryolarÄ± HazÄ±rlayÄ±n

```python
# eval_cases.py
EVAL_CASES = [
    {
        "id": "weather_simple",
        "task": "Ä°stanbul'da hava nasÄ±l?",
        "expected_tool": "get_weather",
        "expected_contains": ["Ä°stanbul", "derece"],
        "max_loops": 3,
        "max_cost": 0.01,
    },
    {
        "id": "weather_compare",
        "task": "Ä°stanbul ve Ankara'nÄ±n hava durumunu karÅŸÄ±laÅŸtÄ±r",
        "expected_tool": "get_weather",
        "expected_contains": ["Ä°stanbul", "Ankara", "karÅŸÄ±laÅŸtÄ±r"],
        "max_loops": 5,
        "max_cost": 0.05,
    },
]
```

### AdÄ±m 2: Eval Runner YazÄ±n

```python
# eval_runner.py
def run_eval(cases):
    results = []
    for case in cases:
        result = agent.run(case["task"])
        
        score = {
            "id": case["id"],
            "success": result.status == "success",
            "correct_tool": result.tool_used == case["expected_tool"],
            "output_valid": all(
                word in result.output 
                for word in case["expected_contains"]
            ),
            "loops": result.loop_count,
            "cost": result.total_cost,
            "latency": result.total_time,
        }
        results.append(score)
    
    return results
```

### AdÄ±m 3: SonuÃ§larÄ± Analiz Edin

```python
# eval_report.py
def print_report(results):
    total = len(results)
    success = sum(1 for r in results if r["success"])
    avg_cost = sum(r["cost"] for r in results) / total
    avg_latency = sum(r["latency"] for r in results) / total
    
    print(f"BaÅŸarÄ± OranÄ±: {success}/{total} ({success/total*100:.1f}%)")
    print(f"Ortalama Maliyet: ${avg_cost:.4f}")
    print(f"Ortalama Gecikme: {avg_latency:.2f}s")
    
    # BaÅŸarÄ±sÄ±z olanlarÄ± gÃ¶ster
    failures = [r for r in results if not r["success"]]
    if failures:
        print(f"\nBaÅŸarÄ±sÄ±z GÃ¶revler ({len(failures)}):")
        for f in failures:
            print(f"  - {f['id']}: loops={f['loops']}, cost=${f['cost']:.4f}")
```

---

## ğŸ“ˆ Metrik Takip Tablosu

Her modÃ¼lÃ¼ tamamladÄ±ÄŸÄ±nÄ±zda bu tabloyu doldurun:

| Metrik | Module 1 | Module 2 | Module 3 | Module 4 | Module 5 | Capstone |
|--------|----------|----------|----------|----------|----------|----------|
| BaÅŸarÄ± OranÄ± | | | | | | |
| Ort. Maliyet | | | | | | |
| Ort. Gecikme | | | | | | |
| Ort. DÃ¶ngÃ¼ | | | | | | |
| Tool BaÅŸarÄ±sÄ± | | | | | | |

---

## ğŸ¯ Optimization Stratejileri

### Maliyet DÃ¼ÅŸÃ¼rme
1. **Model Routing:** Basit gÃ¶revler iÃ§in ucuz model kullan
2. **Context Compression:** Gereksiz mesajlarÄ± kaldÄ±r
3. **Caching:** Tekrarlanan sorgularÄ± cache'le
4. **Early Stopping:** Cevap hazÄ±rsa dÃ¶ngÃ¼yÃ¼ bitir

### HÄ±z ArtÄ±rma
1. **Parallel Tool Execution:** BaÄŸÄ±msÄ±z tool'larÄ± paralel Ã§aÄŸÄ±r
2. **Streaming:** SonuÃ§larÄ± akÄ±ÅŸ halinde dÃ¶ndÃ¼r
3. **Model SeÃ§imi:** Daha hÄ±zlÄ± modeller tercih et

### DoÄŸruluk ArtÄ±rma
1. **Reflection:** Agent'Ä± kendini eleÅŸtirmeye zorla
2. **Validation Tools:** Ã‡Ä±ktÄ±yÄ± doÄŸrulama araÃ§larÄ±yla kontrol et
3. **Better Prompts:** System prompt'larÄ± iyileÅŸtir
4. **Few-Shot Examples:** Ã–rnekler ekle

---

> ğŸ’¡ **Eval olmadan optimization olmaz.** Ã–nce Ã¶lÃ§, sonra iyileÅŸtir. Her deÄŸiÅŸiklikten sonra tekrar Ã¶lÃ§.
