"""
Critic Agent - EleÅŸtirmen Agent
================================
DiÄŸer agent'larÄ±n Ã§Ä±ktÄ±larÄ±nÄ± inceler, eleÅŸtirir ve iyileÅŸtirme Ã¶nerir.

Bu dosya ne yapar?
------------------
CriticAgent, Multi-Agent sisteminin "kalite kontrol" birimidir.
Researcher'Ä±n topladÄ±ÄŸÄ± bilgileri eleÅŸtirel gÃ¶zle inceler ve
eksikleri, hatalarÄ±, iyileÅŸtirme alanlarÄ±nÄ± belirler.

Neden Critic Gerekli?
----------------------
Module 2'de Ã¶ÄŸrendiÄŸimiz "Reflection" (yansÄ±ma) kavramÄ±nÄ± hatÄ±rlayÄ±n:
- Bir agent kendi Ã§Ä±ktÄ±sÄ±nÄ± eleÅŸtirmekte zorlanÄ±r
- FARKLI bir agent (farklÄ± system prompt ile) aynÄ± Ã§Ä±ktÄ±yÄ±
  Ã§ok daha etkili bir ÅŸekilde eleÅŸtirebilir

Bu, gerÃ§ek hayattaki "peer review" (meslektaÅŸ deÄŸerlendirmesi) sÃ¼recine benzer:
- Bir yazar kendi makalesindeki hatalarÄ± gÃ¶remez
- BaÅŸka bir editÃ¶r bu hatalarÄ± kolayca bulur

KullanÄ±m:
    critic = CriticAgent()
    result = await critic.process(researcher_output)
    print(result.content)  # EleÅŸtiri ve Ã¶neriler
"""

import sys
import os
import asyncio

# Proje kÃ¶k dizinini Python path'ine ekle
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from agents.base_agent import BaseAgent, AgentResult


class CriticAgent(BaseAgent):
    """
    EleÅŸtirmen Agent.
    
    Bu agent:
    1. Researcher'Ä±n bulgularÄ±nÄ± alÄ±r
    2. Ä°Ã§eriÄŸi kalite, doÄŸruluk ve kapsamlÄ±lÄ±k aÃ§Ä±sÄ±ndan deÄŸerlendirir
    3. GÃ¼Ã§lÃ¼ yÃ¶nleri ve zayÄ±f yÃ¶nleri belirler
    4. Ä°yileÅŸtirme Ã¶nerileri sunar
    
    Neden ayrÄ± bir agent?
    - EleÅŸtiri, farklÄ± bir bakÄ±ÅŸ aÃ§Ä±sÄ± gerektirir
    - Critic'in system prompt'u "eleÅŸtirel dÃ¼ÅŸÃ¼nme" odaklÄ±dÄ±r
    - DÃ¼ÅŸÃ¼k temperature (0.3) ile tutarlÄ± ve objektif eleÅŸtiri Ã¼retir
    - Module 2'deki Reflection kavramÄ±nÄ± Multi-Agent'a taÅŸÄ±r
    
    KullanÄ±m:
        critic = CriticAgent()
        result = await critic.process(researcher_bulgulari)
        print(result.content)  # EleÅŸtiri raporu
    """
    
    def __init__(self, model: str = None):
        """
        CriticAgent'Ä± baÅŸlat.
        
        Parametreler:
            model: KullanÄ±lacak LLM modeli
        
        Not:
            Temperature 0.3 olarak ayarlanÄ±r Ã§Ã¼nkÃ¼ eleÅŸtiri
            OBJEKTÄ°F ve TUTARLI olmalÄ±dÄ±r. Subjektif yorumlar
            kalite kontrolde istenmeyen bir durumdur.
        """
        super().__init__(
            name="critic",
            role="EleÅŸtirmen",
            model=model,
            temperature=0.3,  # DÃ¼ÅŸÃ¼k temperature = Objektif eleÅŸtiri
        )
    
    def _build_system_prompt(self) -> str:
        """
        Critic'e Ã¶zel system prompt oluÅŸtur.
        
        Bu prompt, LLM'e ÅŸunlarÄ± sÃ¶yler:
        - Sen bir eleÅŸtirmensin
        - Ã‡Ä±ktÄ±yÄ± kalite, doÄŸruluk, kapsam aÃ§Ä±sÄ±ndan deÄŸerlendir
        - GÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nleri belirle
        - YapÄ±cÄ± eleÅŸtiri yap (sadece sorun deÄŸil, Ã§Ã¶zÃ¼m de Ã¶ner)
        
        DÃ¶ndÃ¼rÃ¼r:
            str: Critic system prompt
        """
        return (
            "Sen uzman bir eleÅŸtirmen ve kalite kontrol uzmanÄ±sÄ±n. "
            "Sana verilen iÃ§eriÄŸi dikkatli bir ÅŸekilde incele ve eleÅŸtir.\n\n"
            "DeÄŸerlendirme kriterlerin:\n"
            "1. DOÄRULUK: Bilgiler doÄŸru mu? YanlÄ±ÅŸ veya yanÄ±ltÄ±cÄ± bilgi var mÄ±?\n"
            "2. KAPSAM: Konu yeterince kapsamlÄ± mÄ±? Eksik kalan alan var mÄ±?\n"
            "3. DERÄ°NLÄ°K: Bilgiler yeterince detaylÄ± mÄ±? YÃ¼zeysel mi kalÄ±nmÄ±ÅŸ?\n"
            "4. TUTARLILIK: Ä°Ã§erik kendi iÃ§inde tutarlÄ± mÄ±? Ã‡eliÅŸki var mÄ±?\n"
            "5. KAYNAK: Somut Ã¶rnekler ve veriler var mÄ±?\n\n"
            "Kurallar:\n"
            "- YAPICI eleÅŸtiri yap (sadece sorun deÄŸil, Ã§Ã¶zÃ¼m de Ã¶ner)\n"
            "- GÃ¼Ã§lÃ¼ yÃ¶nleri de belirt (sadece olumsuz deÄŸil)\n"
            "- Her eleÅŸtiri iÃ§in somut iyileÅŸtirme Ã¶nerisi sun\n"
            "- TÃ¼rkÃ§e yaz\n\n"
            "Ã‡Ä±ktÄ± formatÄ±:\n"
            "ELEÅTÄ°RÄ° RAPORU:\n\n"
            "## GÃ¼Ã§lÃ¼ YÃ¶nler\n"
            "- [gÃ¼Ã§lÃ¼ yÃ¶n 1]\n"
            "- [gÃ¼Ã§lÃ¼ yÃ¶n 2]\n\n"
            "## ZayÄ±f YÃ¶nler ve Ä°yileÅŸtirme Ã–nerileri\n"
            "- [zayÄ±f yÃ¶n 1] â†’ Ã–neri: [iyileÅŸtirme]\n"
            "- [zayÄ±f yÃ¶n 2] â†’ Ã–neri: [iyileÅŸtirme]\n\n"
            "## Genel DeÄŸerlendirme\n"
            "[KÄ±sa Ã¶zet ve puan: 1-10]"
        )
    
    async def process(self, input_data: str) -> AgentResult:
        """
        Verilen iÃ§eriÄŸi eleÅŸtir.
        
        Bu metot:
        1. Researcher'Ä±n bulgularÄ±nÄ± alÄ±r
        2. LLM'den eleÅŸtirel deÄŸerlendirme ister
        3. EleÅŸtiri raporunu dÃ¶ndÃ¼rÃ¼r
        
        Parametreler:
            input_data: EleÅŸtirilecek iÃ§erik (genellikle Researcher Ã§Ä±ktÄ±sÄ±)
        
        DÃ¶ndÃ¼rÃ¼r:
            AgentResult: EleÅŸtiri raporu
        
        Ã–rnek:
            result = await critic.process(researcher_bulgulari)
            print(result.content)
            # ELEÅTÄ°RÄ° RAPORU:
            # ## GÃ¼Ã§lÃ¼ YÃ¶nler
            # - Konu Ã§eÅŸitliliÄŸi iyi...
            # ## ZayÄ±f YÃ¶nler ve Ä°yileÅŸtirme Ã–nerileri
            # - Kaynak eksikliÄŸi â†’ Ã–neri: Ä°statistiksel veri ekle
        """
        self.logger.info(f"ğŸ” Ä°Ã§erik eleÅŸtiriliyor...")
        
        # LLM'e eleÅŸtiri yaptÄ±r
        prompt = (
            f"AÅŸaÄŸÄ±daki araÅŸtÄ±rma bulgularÄ±nÄ± eleÅŸtirel bir gÃ¶zle deÄŸerlendir. "
            f"GÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nlerini belirle, iyileÅŸtirme Ã¶nerileri sun.\n\n"
            f"DEÄERLENDÄ°RÄ°LECEK Ä°Ã‡ERÄ°K:\n{input_data}"
        )
        
        response = await self._call_llm(prompt)
        
        return AgentResult(
            agent_name=self.name,
            agent_role=self.role,
            content=response,
            success=bool(response and "[HATA]" not in response),
            metadata={"reviewed_content_length": len(input_data)},
        )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Bu dosyayÄ± doÄŸrudan Ã§alÄ±ÅŸtÄ±rarak test edebilirsiniz:
# cd module-05-multi-agent
# python -m agents.critic
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    async def main():
        print("ğŸ” CriticAgent Test")
        print("=" * 50)
        
        critic = CriticAgent()
        print(f"Agent: {critic}")
        
        # Ã–rnek araÅŸtÄ±rma bulgularÄ± ile eleÅŸtiri yap
        Ã¶rnek_bulgular = (
            "ARAÅTIRMA BULGULARI:\n\n"
            "## AI'Ä±n EÄŸitimdeki Mevcut UygulamalarÄ±\n"
            "Yapay zeka, eÄŸitim sektÃ¶rÃ¼nde birÃ§ok alanda kullanÄ±lmaktadÄ±r. "
            "Adaptif Ã¶ÄŸrenme platformlarÄ±, Ã¶ÄŸrencilerin bireysel hÄ±zlarÄ±na gÃ¶re "
            "iÃ§erik sunar.\n\n"
            "## KiÅŸiselleÅŸtirilmiÅŸ Ã–ÄŸrenme\n"
            "AI destekli sistemler, her Ã¶ÄŸrencinin gÃ¼Ã§lÃ¼ ve zayÄ±f yÃ¶nlerini "
            "analiz ederek kiÅŸiye Ã¶zel mÃ¼fredat oluÅŸturabilir.\n\n"
            "## Gelecek Trendleri\n"
            "AI eÄŸitimde daha da yaygÄ±nlaÅŸacak."
        )
        
        print(f"\nDeÄŸerlendirilecek iÃ§erik uzunluÄŸu: {len(Ã¶rnek_bulgular)} karakter")
        print("-" * 50)
        
        result = await critic.process(Ã¶rnek_bulgular)
        
        print(f"\nSonuÃ§ (baÅŸarÄ±lÄ±: {result.success}):")
        print(result.content)
        
        print("\nâœ… CriticAgent testi tamamlandÄ±!")
    
    asyncio.run(main())
