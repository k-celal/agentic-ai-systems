"""
Improve - Ä°yileÅŸtirme ModÃ¼lÃ¼
===============================
Reflection dÃ¶ngÃ¼sÃ¼nÃ¼n Ã¼Ã§Ã¼ncÃ¼ adÄ±mÄ±: EleÅŸtiriyi dikkate alarak geliÅŸtir.

Bu modÃ¼l tÃ¼m reflection dÃ¶ngÃ¼sÃ¼nÃ¼ orkestra eder:
Generate â†’ Critique â†’ Improve â†’ (Tekrar?)

KullanÄ±m:
    from agent.improve import ReflectiveAgent
    
    agent = ReflectiveAgent(max_reflections=3, quality_threshold=7)
    result = await agent.run("Python sÄ±ralama fonksiyonu yaz")
    
    print(f"Son versiyon: {result.final_content}")
    print(f"Ä°terasyon sayÄ±sÄ±: {result.iterations}")
    print(f"Kalite puanÄ±: {result.final_score}")
"""

import sys
import os
from dataclasses import dataclass, field

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from agent.generate import Generator, GeneratedContent
from agent.critique import Critic, CritiqueResult
from shared.telemetry.logger import get_logger
from shared.telemetry.cost_tracker import CostTracker


@dataclass
class ReflectionResult:
    """
    Reflection dÃ¶ngÃ¼sÃ¼nÃ¼n sonucu.
    
    TÃ¼m iterasyonlarÄ±n geÃ§miÅŸini ve son durumu tutar.
    """
    task: str                                   # Orijinal gÃ¶rev
    final_content: str = ""                     # Son geliÅŸtirilmiÅŸ iÃ§erik
    final_score: int = 0                        # Son kalite puanÄ±
    iterations: int = 0                         # Toplam iterasyon sayÄ±sÄ±
    history: list[dict] = field(default_factory=list)  # TÃ¼m iterasyonlarÄ±n geÃ§miÅŸi
    total_tokens: int = 0                       # Toplam token kullanÄ±mÄ±
    total_cost: float = 0.0                     # Toplam maliyet
    status: str = "pending"                     # pending, completed, max_iterations


@dataclass
class IterationRecord:
    """Tek bir iterasyonun kaydÄ±."""
    iteration: int
    content: str
    score: int
    issues: list[str]
    suggestions: list[str]
    tokens_used: int


class ReflectiveAgent:
    """
    Reflection dÃ¶ngÃ¼sÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±ran ana agent.
    
    Bu agent:
    1. Ä°Ã§erik Ã¼retir (Generate)
    2. Ä°Ã§eriÄŸi eleÅŸtirir (Critique)
    3. EleÅŸtirilere gÃ¶re iyileÅŸtirir (Improve)
    4. Kalite eÅŸiÄŸi aÅŸÄ±lana veya max iterasyona ulaÅŸana kadar tekrarlar
    
    KullanÄ±m:
        agent = ReflectiveAgent(
            max_reflections=3,      # Maksimum 3 iyileÅŸtirme
            quality_threshold=7,     # 7+ puan "yeterli"
        )
        
        result = await agent.run("Python'da Fibonacci fonksiyonu yaz")
        
        print(f"SonuÃ§: {result.status}")
        print(f"Puan: {result.final_score}/10")
        print(f"Ä°terasyon: {result.iterations}")
        print(f"Maliyet: ${result.total_cost:.6f}")
        
        # GeÃ§miÅŸi gÃ¶ster
        for h in result.history:
            print(f"  Ä°terasyon {h['iteration']}: Puan {h['score']}/10")
    """
    
    def __init__(
        self,
        max_reflections: int = 3,
        quality_threshold: int = 7,
        model: str = None,
        validate_fn=None,
    ):
        """
        ReflectiveAgent oluÅŸtur.
        
        Parametreler:
            max_reflections: Maksimum iyileÅŸtirme sayÄ±sÄ±
            quality_threshold: Kabul edilebilir kalite eÅŸiÄŸi (1-10)
            model: KullanÄ±lacak LLM modeli
            validate_fn: DÄ±ÅŸ doÄŸrulama fonksiyonu (isteÄŸe baÄŸlÄ±)
        """
        self.max_reflections = max_reflections
        self.quality_threshold = quality_threshold
        self.validate_fn = validate_fn
        
        # Alt bileÅŸenler
        self.generator = Generator(model=model)
        self.critic = Critic(threshold=quality_threshold, model=model)
        self.logger = get_logger("agent.reflective")
        self.cost_tracker = CostTracker(budget_limit=0.50)
    
    async def run(self, task: str) -> ReflectionResult:
        """
        Reflection dÃ¶ngÃ¼sÃ¼nÃ¼ Ã§alÄ±ÅŸtÄ±r.
        
        Parametreler:
            task: YapÄ±lacak gÃ¶rev
        
        DÃ¶ndÃ¼rÃ¼r:
            ReflectionResult: DÃ¶ngÃ¼nÃ¼n sonucu
        """
        result = ReflectionResult(task=task)
        
        self.logger.info(f"{'='*50}")
        self.logger.info(f"ğŸª Reflection DÃ¶ngÃ¼sÃ¼ BaÅŸlatÄ±lÄ±yor")
        self.logger.info(f"   GÃ¶rev: {task}")
        self.logger.info(f"   Max iterasyon: {self.max_reflections}")
        self.logger.info(f"   Kalite eÅŸiÄŸi: {self.quality_threshold}/10")
        self.logger.info(f"{'='*50}")
        
        # â”€â”€â”€ AdÄ±m 1: Ä°lk Ã¼retim â”€â”€â”€
        self.logger.info(f"\n{'â”€'*40}")
        self.logger.info("ğŸ“ Ä°terasyon 1: Ä°lk Ãœretim")
        
        generated = await self.generator.generate(task)
        current_content = generated.content
        result.total_tokens += generated.token_count
        
        self.logger.info(f"   Ãœretilen: {current_content[:100]}...")
        
        # â”€â”€â”€ Reflection DÃ¶ngÃ¼sÃ¼ â”€â”€â”€
        for i in range(self.max_reflections):
            iteration_num = i + 1
            self.logger.info(f"\n{'â”€'*40}")
            self.logger.info(f"ğŸ”„ Ä°terasyon {iteration_num}: EleÅŸtiri ve Ä°yileÅŸtirme")
            
            # â”€â”€â”€ AdÄ±m 2: EleÅŸtir â”€â”€â”€
            if self.validate_fn:
                # DÄ±ÅŸ doÄŸrulama varsa, Ã¶nce onu Ã§alÄ±ÅŸtÄ±r
                self.logger.info("ğŸ”§ DÄ±ÅŸ doÄŸrulama Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...")
                validation = await self.validate_fn(current_content)
                critique = await self.critic.critique_with_validation(
                    content=current_content,
                    task=task,
                    validation_result=validation,
                )
            else:
                critique = await self.critic.critique(
                    content=current_content,
                    task=task,
                )
            
            result.total_tokens += critique.token_count
            
            # GeÃ§miÅŸe kaydet
            result.history.append({
                "iteration": iteration_num,
                "content_preview": current_content[:200],
                "score": critique.score,
                "issues": critique.issues,
                "suggestions": critique.suggestions,
            })
            
            self.logger.info(f"   ğŸ“Š Puan: {critique.score}/10")
            for issue in critique.issues[:3]:
                self.logger.info(f"   âŒ {issue}")
            for suggestion in critique.suggestions[:3]:
                self.logger.info(f"   ğŸ’¡ {suggestion}")
            
            # â”€â”€â”€ Yeterli mi? â”€â”€â”€
            if critique.is_acceptable:
                self.logger.info(f"\nâœ… Kalite eÅŸiÄŸi aÅŸÄ±ldÄ±! ({critique.score}/{self.quality_threshold})")
                result.final_content = current_content
                result.final_score = critique.score
                result.iterations = iteration_num
                result.status = "completed"
                break
            
            # â”€â”€â”€ AdÄ±m 3: Ä°yileÅŸtir â”€â”€â”€
            feedback = self._format_feedback(critique)
            
            improved = await self.generator.regenerate(
                task=task,
                previous_content=current_content,
                feedback=feedback,
                iteration=iteration_num + 1,
            )
            
            current_content = improved.content
            result.total_tokens += improved.token_count
            
            self.logger.info(f"   âœï¸ Ä°Ã§erik gÃ¼ncellendi ({len(current_content)} karakter)")
        
        else:
            # Max iterasyona ulaÅŸÄ±ldÄ±
            self.logger.info(f"\nâš ï¸ Maksimum iterasyona ulaÅŸÄ±ldÄ± ({self.max_reflections})")
            result.final_content = current_content
            result.final_score = critique.score if 'critique' in dir() else 0
            result.iterations = self.max_reflections
            result.status = "max_iterations"
        
        # Maliyet hesapla
        result.total_cost = self.cost_tracker.calculate_cost(
            result.total_tokens, 0
        )
        
        # SonuÃ§ raporu
        self._print_summary(result)
        
        return result
    
    def _format_feedback(self, critique: CritiqueResult) -> str:
        """EleÅŸtiriyi iyileÅŸtirme iÃ§in formatlÄ± geri bildirime dÃ¶nÃ¼ÅŸtÃ¼r."""
        lines = [f"Kalite PuanÄ±: {critique.score}/10\n"]
        
        if critique.issues:
            lines.append("Sorunlar:")
            for issue in critique.issues:
                lines.append(f"  - {issue}")
        
        if critique.suggestions:
            lines.append("\nÃ–neriler:")
            for suggestion in critique.suggestions:
                lines.append(f"  - {suggestion}")
        
        return "\n".join(lines)
    
    def _print_summary(self, result: ReflectionResult):
        """DÃ¶ngÃ¼ Ã¶zet raporu yazdÄ±r."""
        self.logger.info(f"\n{'='*50}")
        self.logger.info(f"ğŸ“Š Reflection Ã–zet Raporu")
        self.logger.info(f"{'='*50}")
        self.logger.info(f"GÃ¶rev:       {result.task}")
        self.logger.info(f"Durum:       {result.status}")
        self.logger.info(f"Son Puan:    {result.final_score}/10")
        self.logger.info(f"Ä°terasyon:   {result.iterations}")
        self.logger.info(f"Token:       {result.total_tokens:,}")
        self.logger.info(f"Tahmini Maliyet: ${result.total_cost:.6f}")
        
        if result.history:
            self.logger.info(f"\nPuan GeÃ§miÅŸi:")
            for h in result.history:
                self.logger.info(f"  Ä°terasyon {h['iteration']}: {h['score']}/10")
        
        self.logger.info(f"{'='*50}")
