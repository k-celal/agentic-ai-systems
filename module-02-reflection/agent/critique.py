"""
Critique - EleÅŸtiri ModÃ¼lÃ¼
============================
Reflection dÃ¶ngÃ¼sÃ¼nÃ¼n ikinci adÄ±mÄ±: Ãœretilen iÃ§eriÄŸi eleÅŸtir.

EleÅŸtiri neden Ã¶nemli?
---------------------
Ä°lk Ã¼retim genellikle "yeterli" ama "mÃ¼kemmel" deÄŸildir.
EleÅŸtiri aÅŸamasÄ±, eksiklikleri ve hatalarÄ± tespit eder.

Ä°ki tÃ¼r eleÅŸtiri:
1. Self-Critique (Ã–z EleÅŸtiri): LLM kendi Ã§Ä±ktÄ±sÄ±nÄ± eleÅŸtirir
2. External Validation: DÄ±ÅŸ bir araÃ§/sistem ile doÄŸrulama

KullanÄ±m:
    from agent.critique import Critic
    
    critic = Critic()
    feedback = await critic.critique(content, task)
    print(feedback.issues)     # Bulunan sorunlar
    print(feedback.score)      # Kalite puanÄ± (1-10)
    print(feedback.suggestions) # Ä°yileÅŸtirme Ã¶nerileri
"""

import sys
import os
import json
from dataclasses import dataclass, field

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from shared.llm.client import LLMClient
from shared.telemetry.logger import get_logger
from shared.utils.helpers import parse_json_safely


@dataclass
class CritiqueResult:
    """
    EleÅŸtiri sonucunu temsil eder.
    
    Attributes:
        score: Kalite puanÄ± (1-10, 10=mÃ¼kemmel)
        issues: Tespit edilen sorunlar listesi
        suggestions: Ä°yileÅŸtirme Ã¶nerileri
        is_acceptable: Kabul edilebilir mi? (score >= threshold)
        token_count: KullanÄ±lan token sayÄ±sÄ±
    """
    score: int = 5
    issues: list[str] = field(default_factory=list)
    suggestions: list[str] = field(default_factory=list)
    is_acceptable: bool = False
    raw_feedback: str = ""
    token_count: int = 0


class Critic:
    """
    Ä°Ã§erik eleÅŸtirmeni.
    
    Ãœretilen iÃ§eriÄŸi analiz eder ve geri bildirim verir.
    
    KullanÄ±m:
        critic = Critic(threshold=7)
        
        feedback = await critic.critique(
            content="def sort(lst): return sorted(lst)",
            task="Python sÄ±ralama fonksiyonu yaz"
        )
        
        if feedback.is_acceptable:
            print("Ä°Ã§erik kabul edildi!")
        else:
            print(f"Sorunlar: {feedback.issues}")
            print(f"Ã–neriler: {feedback.suggestions}")
    """
    
    def __init__(self, threshold: int = 7, model: str = None):
        """
        Critic oluÅŸtur.
        
        Parametreler:
            threshold: Kabul eÅŸiÄŸi (bu puan ve Ã¼zeri "kabul edilir")
            model: KullanÄ±lacak LLM modeli
        """
        self.threshold = threshold
        self.llm = LLMClient(model=model)
        self.logger = get_logger("agent.critique")
    
    async def critique(
        self,
        content: str,
        task: str,
        criteria: list[str] = None,
    ) -> CritiqueResult:
        """
        Ä°Ã§eriÄŸi eleÅŸtir.
        
        Parametreler:
            content: EleÅŸtirilecek iÃ§erik
            task: Orijinal gÃ¶rev (baÄŸlam iÃ§in)
            criteria: DeÄŸerlendirme kriterleri (isteÄŸe baÄŸlÄ±)
        
        DÃ¶ndÃ¼rÃ¼r:
            CritiqueResult: EleÅŸtiri sonucu
        
        Ã–rnek:
            result = await critic.critique(
                content="print('hello')",
                task="Python'da merhaba dÃ¼nya programÄ± yaz",
                criteria=["Okunabilirlik", "DoÄŸruluk", "TamlÄ±k"]
            )
        """
        self.logger.info("ğŸ” Ä°Ã§erik eleÅŸtiriliyor...")
        
        # VarsayÄ±lan kriterler
        if criteria is None:
            criteria = [
                "DoÄŸruluk (iÃ§erik faktÃ¼el olarak doÄŸru mu?)",
                "TamlÄ±k (gÃ¶revin tÃ¼m gereksinimleri karÅŸÄ±lanmÄ±ÅŸ mÄ±?)",
                "AÃ§Ä±klÄ±k (anlaÅŸÄ±lÄ±r mÄ±?)",
                "Kalite (iyi yazÄ±lmÄ±ÅŸ mÄ±?)",
            ]
        
        criteria_text = "\n".join(f"- {c}" for c in criteria)
        
        response = await self.llm.chat(
            message=(
                f"## GÃ¶rev\n{task}\n\n"
                f"## Ãœretilen Ä°Ã§erik\n{content}\n\n"
                f"## DeÄŸerlendirme Kriterleri\n{criteria_text}\n\n"
                "YukarÄ±daki iÃ§eriÄŸi deÄŸerlendir."
            ),
            system_prompt=(
                "Sen sÄ±kÄ± bir iÃ§erik eleÅŸtirmenisin. Verilen iÃ§eriÄŸi objektif deÄŸerlendir.\n\n"
                "MUTLAKA aÅŸaÄŸÄ±daki JSON formatÄ±nda yanÄ±t ver:\n"
                '{\n'
                '  "score": 1-10 arasÄ± puan,\n'
                '  "issues": ["sorun 1", "sorun 2", ...],\n'
                '  "suggestions": ["Ã¶neri 1", "Ã¶neri 2", ...]\n'
                '}\n\n'
                "Kurallar:\n"
                "- 1-3: Ã‡ok kÃ¶tÃ¼, ciddi sorunlar var\n"
                "- 4-6: Orta, iyileÅŸtirme gerekli\n"
                "- 7-8: Ä°yi, kÃ¼Ã§Ã¼k dÃ¼zeltmeler yeterli\n"
                "- 9-10: MÃ¼kemmel, deÄŸiÅŸiklik gerekmez\n"
                "- DÃ¼rÃ¼st ve yapÄ±cÄ± ol\n"
                "- Her sorun iÃ§in somut Ã¶neri ver"
            ),
        )
        
        # CevabÄ± parse et
        result = self._parse_critique(response.content or "")
        result.token_count = response.usage.total_tokens
        result.is_acceptable = result.score >= self.threshold
        
        self.logger.info(f"ğŸ“Š Puan: {result.score}/10 | Kabul: {'âœ…' if result.is_acceptable else 'âŒ'}")
        self.logger.info(f"   Sorunlar: {len(result.issues)} | Ã–neriler: {len(result.suggestions)}")
        
        return result
    
    async def critique_with_validation(
        self,
        content: str,
        task: str,
        validation_result: dict,
    ) -> CritiqueResult:
        """
        DÄ±ÅŸ doÄŸrulama sonucu ile birlikte eleÅŸtir.
        
        MCP validation tool'unun sonucunu da dikkate alÄ±r.
        
        Parametreler:
            content: EleÅŸtirilecek iÃ§erik
            task: Orijinal gÃ¶rev
            validation_result: Validation tool sonucu
        
        DÃ¶ndÃ¼rÃ¼r:
            CritiqueResult: EleÅŸtiri sonucu
        """
        self.logger.info("ğŸ” Ä°Ã§erik eleÅŸtiriliyor (validation sonucu ile)...")
        
        response = await self.llm.chat(
            message=(
                f"## GÃ¶rev\n{task}\n\n"
                f"## Ãœretilen Ä°Ã§erik\n{content}\n\n"
                f"## DoÄŸrulama Sonucu\n{json.dumps(validation_result, ensure_ascii=False, indent=2)}\n\n"
                "Hem iÃ§eriÄŸi hem de doÄŸrulama sonuÃ§larÄ±nÄ± deÄŸerlendir."
            ),
            system_prompt=(
                "Sen bir kalite kontrol uzmanÄ±sÄ±n. Ä°Ã§eriÄŸi ve doÄŸrulama sonuÃ§larÄ±nÄ± deÄŸerlendir.\n\n"
                "MUTLAKA aÅŸaÄŸÄ±daki JSON formatÄ±nda yanÄ±t ver:\n"
                '{\n'
                '  "score": 1-10 arasÄ± puan,\n'
                '  "issues": ["sorun 1", "sorun 2", ...],\n'
                '  "suggestions": ["Ã¶neri 1", "Ã¶neri 2", ...]\n'
                '}'
            ),
        )
        
        result = self._parse_critique(response.content or "")
        result.token_count = response.usage.total_tokens
        result.is_acceptable = result.score >= self.threshold
        
        return result
    
    def _parse_critique(self, text: str) -> CritiqueResult:
        """LLM cevabÄ±nÄ± CritiqueResult'a dÃ¶nÃ¼ÅŸtÃ¼r."""
        parsed = parse_json_safely(text)
        
        if parsed:
            return CritiqueResult(
                score=min(10, max(1, int(parsed.get("score", 5)))),
                issues=parsed.get("issues", []),
                suggestions=parsed.get("suggestions", []),
                raw_feedback=text,
            )
        
        # JSON parse edilemezse, ham metni kullan
        return CritiqueResult(
            score=5,
            issues=["EleÅŸtiri JSON formatÄ±nda deÄŸil"],
            suggestions=["Ä°Ã§eriÄŸi tekrar deÄŸerlendir"],
            raw_feedback=text,
        )
