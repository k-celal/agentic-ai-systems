"""
Generate - Ä°Ã§erik Ãœretici
===========================
Reflection dÃ¶ngÃ¼sÃ¼nÃ¼n ilk adÄ±mÄ±: Ä°lk Ã§Ä±ktÄ±yÄ± Ã¼ret.

Bu modÃ¼l ne yapar?
-----------------
Verilen bir gÃ¶rev iÃ§in ilk taslak Ã§Ä±ktÄ±yÄ± Ã¼retir.
Bu Ã§Ä±ktÄ± mÃ¼kemmel olmak zorunda deÄŸil â€” eleÅŸtiri ve
iyileÅŸtirme aÅŸamalarÄ±nda geliÅŸtirilecek.

KullanÄ±m:
    from agent.generate import Generator
    
    gen = Generator()
    draft = await gen.generate("Python'da fibonacci fonksiyonu yaz")
    print(draft.content)
"""

import sys
import os
from dataclasses import dataclass

sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from shared.llm.client import LLMClient
from shared.telemetry.logger import get_logger


@dataclass
class GeneratedContent:
    """
    Ãœretilen iÃ§eriÄŸi temsil eder.
    
    Attributes:
        content: Ãœretilen metin
        task: Orijinal gÃ¶rev
        iteration: KaÃ§Ä±ncÄ± iterasyon (1 = ilk Ã¼retim)
        token_count: KullanÄ±lan token sayÄ±sÄ±
    """
    content: str
    task: str
    iteration: int = 1
    token_count: int = 0


class Generator:
    """
    Ä°Ã§erik Ã¼retici.
    
    Verilen gÃ¶rev iÃ§in LLM kullanarak iÃ§erik Ã¼retir.
    Reflection dÃ¶ngÃ¼sÃ¼nÃ¼n "Generate" aÅŸamasÄ±dÄ±r.
    
    KullanÄ±m:
        gen = Generator()
        
        # Ä°lk Ã¼retim
        draft = await gen.generate("Python sÄ±ralama fonksiyonu yaz")
        
        # EleÅŸtiriden sonra yeniden Ã¼retim (feedback ile)
        improved = await gen.regenerate(
            task="Python sÄ±ralama fonksiyonu yaz",
            previous_content=draft.content,
            feedback="Docstring ekle ve type hint kullan"
        )
    """
    
    def __init__(self, model: str = None):
        self.llm = LLMClient(model=model)
        self.logger = get_logger("agent.generate")
    
    async def generate(self, task: str) -> GeneratedContent:
        """
        GÃ¶rev iÃ§in ilk iÃ§eriÄŸi Ã¼ret.
        
        Parametreler:
            task: YapÄ±lacak gÃ¶rev
        
        DÃ¶ndÃ¼rÃ¼r:
            GeneratedContent: Ãœretilen iÃ§erik
        
        Ã–rnek:
            draft = await gen.generate("E-posta taslaÄŸÄ± yaz")
            print(draft.content)
        """
        self.logger.info(f"ğŸ“ Ä°Ã§erik Ã¼retiliyor: {task}")
        
        response = await self.llm.chat(
            message=task,
            system_prompt=(
                "Sen bir iÃ§erik Ã¼reticisisin. Verilen gÃ¶revi en iyi ÅŸekilde tamamla.\n"
                "AÃ§Ä±k, anlaÅŸÄ±lÄ±r ve kaliteli iÃ§erik Ã¼ret.\n"
                "TÃ¼rkÃ§e yanÄ±t ver."
            ),
        )
        
        content = response.content or "[Ãœretim baÅŸarÄ±sÄ±z]"
        
        self.logger.info(f"âœ… Ä°Ã§erik Ã¼retildi ({len(content)} karakter)")
        
        return GeneratedContent(
            content=content,
            task=task,
            iteration=1,
            token_count=response.usage.total_tokens,
        )
    
    async def regenerate(
        self,
        task: str,
        previous_content: str,
        feedback: str,
        iteration: int = 2,
    ) -> GeneratedContent:
        """
        EleÅŸtiriden sonra iÃ§eriÄŸi yeniden Ã¼ret.
        
        Bu fonksiyon, Ã¶nceki Ã¼retimi ve eleÅŸtiriyi dikkate alarak
        geliÅŸtirilmiÅŸ bir versiyon Ã¼retir.
        
        Parametreler:
            task: Orijinal gÃ¶rev
            previous_content: Ã–nceki Ã¼retilen iÃ§erik
            feedback: EleÅŸtiri/geri bildirim
            iteration: KaÃ§Ä±ncÄ± iterasyon
        
        DÃ¶ndÃ¼rÃ¼r:
            GeneratedContent: GeliÅŸtirilmiÅŸ iÃ§erik
        """
        self.logger.info(f"ğŸ”„ Ä°Ã§erik yeniden Ã¼retiliyor (iterasyon {iteration})")
        
        response = await self.llm.chat(
            message=(
                f"## Orijinal GÃ¶rev\n{task}\n\n"
                f"## Ã–nceki Ãœretim\n{previous_content}\n\n"
                f"## EleÅŸtiri ve Geri Bildirim\n{feedback}\n\n"
                f"YukarÄ±daki eleÅŸtirileri dikkate alarak iÃ§eriÄŸi geliÅŸtir. "
                f"Sadece geliÅŸtirilmiÅŸ versiyonu yaz."
            ),
            system_prompt=(
                "Sen bir iÃ§erik geliÅŸtirme uzmanÄ±sÄ±n. "
                "Verilen eleÅŸtirileri dikkate alarak iÃ§eriÄŸi iyileÅŸtir.\n"
                "EleÅŸtirilerdeki her noktayÄ± adresle.\n"
                "TÃ¼rkÃ§e yanÄ±t ver."
            ),
        )
        
        content = response.content or previous_content
        
        self.logger.info(f"âœ… Ä°Ã§erik geliÅŸtirildi ({len(content)} karakter)")
        
        return GeneratedContent(
            content=content,
            task=task,
            iteration=iteration,
            token_count=response.usage.total_tokens,
        )
