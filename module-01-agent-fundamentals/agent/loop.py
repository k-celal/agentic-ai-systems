"""
Agent Loop - Agent Ã‡alÄ±ÅŸma DÃ¶ngÃ¼sÃ¼
====================================
Bu dosya, bir agent'Ä±n kalbini oluÅŸturur: Ã§alÄ±ÅŸma dÃ¶ngÃ¼sÃ¼.

Agent DÃ¶ngÃ¼sÃ¼ Nedir?
--------------------
Bir agent, ÅŸu adÄ±mlarÄ± tekrarlar:
1. DÃœÅÃœN (Think)    â†’ GÃ¶revi analiz et
2. KARAR VER (Decide) â†’ Ne yapacaÄŸÄ±na karar ver
3. YÃœRÃœT (Act)      â†’ Tool Ã§aÄŸÄ±r veya cevap ver
4. GÃ–ZLEMLE (Observe) â†’ Sonucu deÄŸerlendir

Bu dÃ¶ngÃ¼, gÃ¶rev tamamlanana veya limit aÅŸÄ±lana kadar devam eder.

KullanÄ±m:
    from agent.loop import AgentLoop
    
    agent = AgentLoop(tools=my_tools)
    result = await agent.run("Ä°stanbul'da saat kaÃ§?")
    print(result)
"""

import sys
import os
import json
import asyncio
from dataclasses import dataclass, field
from typing import Optional

# Proje kÃ¶k dizinini Python path'ine ekle
# Bu sayede 'shared' modÃ¼lÃ¼nÃ¼ import edebiliriz
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", ".."))

from shared.llm.client import LLMClient, LLMResponse
from shared.telemetry.logger import get_logger, AgentTracer
from shared.telemetry.cost_tracker import CostTracker
from shared.utils.helpers import format_tool_result


# ============================================================
# Agent Durumu (State)
# ============================================================

@dataclass
class AgentState:
    """
    Agent'Ä±n mevcut durumunu tutar.
    
    Neden durum takibi?
    - Agent dÃ¶ngÃ¼de Ã§alÄ±ÅŸÄ±r, her adÄ±mda durumu gÃ¼ncellenir
    - KaÃ§ dÃ¶ngÃ¼ geÃ§ti? GÃ¶rev bitti mi? Hata var mÄ±?
    - Bu bilgiler dÃ¶ngÃ¼nÃ¼n ne yapacaÄŸÄ±na karar vermesini saÄŸlar
    """
    task: str = ""                          # KullanÄ±cÄ±nÄ±n verdiÄŸi gÃ¶rev
    messages: list = field(default_factory=list)  # Mesaj geÃ§miÅŸi
    current_step: int = 0                   # Åu anki adÄ±m numarasÄ±
    status: str = "idle"                    # idle, running, completed, failed
    final_answer: Optional[str] = None      # Agent'Ä±n son cevabÄ±
    tool_results: list = field(default_factory=list)  # Tool sonuÃ§larÄ± geÃ§miÅŸi


# ============================================================
# Agent DÃ¶ngÃ¼sÃ¼ (Ana SÄ±nÄ±f)
# ============================================================

class AgentLoop:
    """
    Agent'Ä±n Ã§alÄ±ÅŸma dÃ¶ngÃ¼sÃ¼.
    
    Bu sÄ±nÄ±f, agent'Ä±n "beyni"dir:
    1. KullanÄ±cÄ±dan bir gÃ¶rev alÄ±r
    2. LLM'e sorarak plan yapar
    3. Gerekirse tool Ã§aÄŸÄ±rÄ±r
    4. Sonucu deÄŸerlendirir
    5. GÃ¶rev tamamlanana kadar tekrarlar
    
    KullanÄ±m:
        # Tool'larÄ± tanÄ±mla
        tools = {
            "echo": echo_function,
            "get_time": time_function,
        }
        
        # Tool ÅŸemalarÄ±nÄ± tanÄ±mla (LLM'in tool'larÄ± bilmesi iÃ§in)
        tool_schemas = [echo_schema, time_schema]
        
        # Agent'Ä± oluÅŸtur
        agent = AgentLoop(
            tools=tools,
            tool_schemas=tool_schemas,
            max_loops=5,
        )
        
        # GÃ¶revi Ã§alÄ±ÅŸtÄ±r
        result = await agent.run("Bana ÅŸu anki saati sÃ¶yle")
        print(result.final_answer)
    """
    
    def __init__(
        self,
        tools: dict = None,
        tool_schemas: list = None,
        max_loops: int = 5,
        system_prompt: str = None,
        model: str = None,
    ):
        """
        Agent dÃ¶ngÃ¼sÃ¼nÃ¼ baÅŸlat.
        
        Parametreler:
            tools: KullanÄ±labilir tool fonksiyonlarÄ± {"isim": fonksiyon}
            tool_schemas: Tool ÅŸemalarÄ± (OpenAI formatÄ±nda)
            max_loops: Maksimum dÃ¶ngÃ¼ sayÄ±sÄ± (sonsuz dÃ¶ngÃ¼ korumasÄ±!)
            system_prompt: Agent'a verilen talimat
            model: KullanÄ±lacak LLM modeli
        """
        self.tools = tools or {}
        self.tool_schemas = tool_schemas or []
        self.max_loops = max_loops
        self.model = model
        
        # VarsayÄ±lan system prompt
        self.system_prompt = system_prompt or (
            "Sen yardÄ±mcÄ± bir AI agent'sÄ±n. Sana verilen gÃ¶revi tamamlamak iÃ§in "
            "tool'larÄ± kullanabilirsin. Her adÄ±mda ne yapacaÄŸÄ±nÄ± dÃ¼ÅŸÃ¼n ve en uygun "
            "tool'u Ã§aÄŸÄ±r. GÃ¶rev tamamlandÄ±ÄŸÄ±nda son cevabÄ±nÄ± ver.\n\n"
            "Kurallar:\n"
            "1. Tool Ã§aÄŸÄ±rmadan Ã¶nce neden Ã§aÄŸÄ±rdÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼n\n"
            "2. Tool sonucunu deÄŸerlendir\n"
            "3. GÃ¶rev tamamlandÄ±ysa son cevabÄ±nÄ± ver\n"
            "4. Emin deÄŸilsen daha fazla bilgi topla"
        )
        
        # LLM istemcisi
        self.llm = LLMClient(model=model)
        
        # Loglama ve izleme
        self.logger = get_logger("agent.loop")
        self.tracer = AgentTracer("module-01-agent")
        self.cost_tracker = CostTracker(budget_limit=0.50)
    
    async def run(self, task: str) -> AgentState:
        """
        Bir gÃ¶revi Ã§alÄ±ÅŸtÄ±r.
        
        Bu fonksiyon agent dÃ¶ngÃ¼sÃ¼nÃ¼ baÅŸlatÄ±r ve gÃ¶rev
        tamamlanana kadar Ã§alÄ±ÅŸtÄ±rÄ±r.
        
        Parametreler:
            task: KullanÄ±cÄ±nÄ±n verdiÄŸi gÃ¶rev
        
        DÃ¶ndÃ¼rÃ¼r:
            AgentState: Agent'Ä±n son durumu
        
        Ã–rnek:
            result = await agent.run("Åu anki saati sÃ¶yle")
            if result.status == "completed":
                print(f"Cevap: {result.final_answer}")
            else:
                print(f"BaÅŸarÄ±sÄ±z: {result.status}")
        """
        # Agent durumunu baÅŸlat
        state = AgentState(task=task, status="running")
        
        # Ä°zlemeyi baÅŸlat
        self.tracer.start_task(task)
        
        # Mesaj geÃ§miÅŸini baÅŸlat
        state.messages = [
            {"role": "system", "content": self.system_prompt},
            {"role": "user", "content": task},
        ]
        
        self.logger.info(f"ğŸš€ GÃ¶rev baÅŸlatÄ±ldÄ±: {task}")
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ANA DÃ–NGÃœ â€” Agent'Ä±n kalbi burada atar
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        for step in range(self.max_loops):
            state.current_step = step + 1
            self.logger.info(f"\n{'â”€'*40}")
            self.logger.info(f"ğŸ“ AdÄ±m {state.current_step}/{self.max_loops}")
            
            # â”€â”€â”€ 1. DÃœÅÃœN ve KARAR VER â”€â”€â”€
            # LLM'e mevcut durumu gÃ¶ster, ne yapacaÄŸÄ±na karar versin
            self.logger.info("ğŸ§  DÃ¼ÅŸÃ¼nÃ¼yor...")
            
            response = await self.llm.chat_with_messages(
                messages=state.messages,
                tools=self.tool_schemas if self.tool_schemas else None,
            )
            
            # Maliyet takibi
            self.cost_tracker.add_usage(
                input_tokens=response.usage.input_tokens,
                output_tokens=response.usage.output_tokens,
                model=response.model,
                label=f"step_{state.current_step}",
            )
            
            # â”€â”€â”€ 2. YÃœRÃœT â”€â”€â”€
            if response.has_tool_calls:
                # LLM bir tool Ã§aÄŸÄ±rmak istiyor
                for tool_call in response.tool_calls:
                    self.logger.info(f"ğŸ”§ Tool Ã§aÄŸrÄ±lÄ±yor: {tool_call.name}({tool_call.arguments})")
                    self.tracer.log_tool_call(tool_call.name, tool_call.arguments)
                    
                    # Tool'u Ã§alÄ±ÅŸtÄ±r
                    tool_result = await self._execute_tool(tool_call.name, tool_call.arguments)
                    
                    self.logger.info(f"ğŸ“¥ Tool sonucu: {tool_result[:100]}")
                    self.tracer.log_tool_result(tool_call.name, tool_result)
                    
                    # Tool sonucunu geÃ§miÅŸe ekle
                    state.messages.append({
                        "role": "assistant",
                        "content": None,
                        "tool_calls": [{
                            "id": tool_call.id,
                            "type": "function",
                            "function": {
                                "name": tool_call.name,
                                "arguments": json.dumps(tool_call.arguments),
                            },
                        }],
                    })
                    state.messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "content": tool_result,
                    })
                    
                    state.tool_results.append({
                        "tool": tool_call.name,
                        "args": tool_call.arguments,
                        "result": tool_result,
                    })
            
            elif response.content:
                # LLM bir metin cevabÄ± verdi â†’ GÃ¶rev tamamlanmÄ±ÅŸ olabilir
                self.logger.info(f"ğŸ’¬ Cevap: {response.content[:200]}")
                self.tracer.log_response(response.content)
                
                state.final_answer = response.content
                state.status = "completed"
                
                # Mesaj geÃ§miÅŸine ekle
                state.messages.append({
                    "role": "assistant",
                    "content": response.content,
                })
                
                break
            
            # â”€â”€â”€ 3. GÃ–ZLEMLE â”€â”€â”€
            # BÃ¼tÃ§e kontrolÃ¼
            if self.cost_tracker.is_over_budget():
                self.logger.warning("âš ï¸ BÃ¼tÃ§e aÅŸÄ±ldÄ±! DÃ¶ngÃ¼ durduruluyor.")
                state.status = "budget_exceeded"
                break
        
        else:
            # DÃ¶ngÃ¼ max_loops'a ulaÅŸtÄ±
            self.logger.warning(f"âš ï¸ Maksimum dÃ¶ngÃ¼ sayÄ±sÄ±na ulaÅŸÄ±ldÄ± ({self.max_loops})")
            state.status = "max_loops_exceeded"
        
        # Ä°zlemeyi sonlandÄ±r
        self.tracer.end_task(success=(state.status == "completed"))
        
        # Rapor yazdÄ±r
        self.logger.info(self.tracer.get_summary())
        self.logger.info(self.cost_tracker.get_report())
        
        return state
    
    async def _execute_tool(self, tool_name: str, arguments: dict) -> str:
        """
        Bir tool'u Ã§alÄ±ÅŸtÄ±r.
        
        Bu fonksiyon:
        1. Tool'un var olup olmadÄ±ÄŸÄ±nÄ± kontrol eder
        2. Tool fonksiyonunu Ã§aÄŸÄ±rÄ±r
        3. Sonucu string formatÄ±nda dÃ¶ndÃ¼rÃ¼r
        
        Parametreler:
            tool_name: Ã‡aÄŸrÄ±lacak tool'un adÄ±
            arguments: Tool'a gÃ¶nderilecek parametreler
        
        DÃ¶ndÃ¼rÃ¼r:
            str: Tool sonucu (string formatÄ±nda)
        """
        # Tool var mÄ±?
        if tool_name not in self.tools:
            error_msg = f"Hata: '{tool_name}' adÄ±nda bir tool bulunamadÄ±. Mevcut tool'lar: {list(self.tools.keys())}"
            self.tracer.log_error(error_msg)
            return error_msg
        
        try:
            # Tool fonksiyonunu Ã§aÄŸÄ±r
            tool_func = self.tools[tool_name]
            
            # Async mi sync mi?
            if asyncio.iscoroutinefunction(tool_func):
                result = await tool_func(**arguments)
            else:
                result = tool_func(**arguments)
            
            return format_tool_result(result)
        
        except Exception as e:
            error_msg = f"Tool hatasÄ± ({tool_name}): {str(e)}"
            self.tracer.log_error(error_msg)
            return error_msg
